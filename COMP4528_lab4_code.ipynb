{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMP4528 Lab4\n",
    "\n",
    "In this lab, we'll delve into the implementation of deep neural networks for computer vision classification using PyTorch. It's essential to have a solid understanding of PyTorch programming for Assignment 2.\n",
    "\n",
    "In this lab, we will cover:\n",
    "- Implement PyTorch Dataset and DataLoader classes\n",
    "- Implement a simple fully-connected network\n",
    "- Implement a convolutional neural network\n",
    "- Implement the training and testing function for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/duxuke/anaconda3/lib/python3.11/site-packages (2.2.1)\n",
      "Requirement already satisfied: filelock in /Users/duxuke/anaconda3/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/duxuke/anaconda3/lib/python3.11/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /Users/duxuke/anaconda3/lib/python3.11/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/duxuke/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/duxuke/anaconda3/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/duxuke/anaconda3/lib/python3.11/site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/duxuke/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/duxuke/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch torchvision\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 20\n",
    "batch_size = 64\n",
    "lr = 1e-3\n",
    "betas = (0.9, 0.999)\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "# make results determinstic\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMNIST(Dataset):\n",
    "    # TODO: Implement the KMNIST Dataset class according to the PyTorch tutorial\n",
    "    #       https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files\n",
    "    def __init__(self, img_path, label_path, transforms):\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: transformation defined for this classification task, data augmentation techniques used during training.\n",
    "#       To understand each transformation, please read https://pytorch.org/vision/stable/transforms.html\n",
    "#       - (Normalize data to range between [-1, 1])\n",
    "#       - (Randomly flip the image left to right)\n",
    "#       - (Zero-pad 4 pixels on each side and randomly crop 28x28 as input)\n",
    "train_transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5,), (0.5,)),\n",
    "    T.RandomCrop(size=(28, 28), padding=4),\n",
    "])\n",
    "\n",
    "test_transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5,), (0.5,)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load training, validation and testing data use the Dataset and transformations defined above.\n",
    "#       Then, for each dataset, create the corresponding DataLoader class with batch_size provided\n",
    "#       https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#preparing-your-data-for-training-with-dataloaders\n",
    "train_dataset = None\n",
    "val_dataset = None\n",
    "test_dataset = None\n",
    "train_loader = None\n",
    "val_loader = None\n",
    "test_loader = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FcClassifier(nn.Module):\n",
    "    # TODO: Implement a fully-connected neural network with an architecture listed below\n",
    "    #       - Fully-connected layer with 512 output units.\n",
    "    #       - ReLU Activation Layer.\n",
    "    #       - Fully-connected layer with 128 output units.\n",
    "    #       - ReLU Activation Layer.\n",
    "    #       - Fully-connected layer with 10 output units.\n",
    "    #       https://pytorch.org/tutorials/recipes/recipes/defining_a_neural_network.html\n",
    "    def __init__(self):\n",
    "        super(FcClassifier, self).__init__()\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # NOTE: Flatten has been done\n",
    "        x = x.view(x.size(0), -1)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, device, optimizer, n_epoch):\n",
    "    # TODO: Implement training code, you should `print out` training and validation accuracy and loss during training\n",
    "    #       You should define the loss function (cross-entropy loss) within this function\n",
    "    #       Remember to load the best state_dict (highest validation accuracy) before exiting this function, so you are not overfitting.\n",
    "    #       https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "    model.train()\n",
    "    pass\n",
    "\n",
    "\n",
    "def test(model, test_loader, device):\n",
    "    # TODO: Implement testing code, you should `RETURN` the testing accuracy and loss on the given test_loader\n",
    "    #       You should define the loss function (cross-entropy loss) within this function\n",
    "    model.eval()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m FcClassifier()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbetas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbetas\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda/anaconda3/envs/pythonforcomputervision/lib/python3.11/site-packages/torch/optim/adam.py:45\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weight_decay value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_decay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(lr\u001b[38;5;241m=\u001b[39mlr, betas\u001b[38;5;241m=\u001b[39mbetas, eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m     42\u001b[0m                 weight_decay\u001b[38;5;241m=\u001b[39mweight_decay, amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m     43\u001b[0m                 maximize\u001b[38;5;241m=\u001b[39mmaximize, foreach\u001b[38;5;241m=\u001b[39mforeach, capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[1;32m     44\u001b[0m                 differentiable\u001b[38;5;241m=\u001b[39mdifferentiable, fused\u001b[38;5;241m=\u001b[39mfused)\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "File \u001b[0;32m/Applications/anaconda/anaconda3/envs/pythonforcomputervision/lib/python3.11/site-packages/torch/optim/optimizer.py:273\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    271\u001b[0m param_groups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(params)\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(param_groups) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer got an empty parameter list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(param_groups[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    275\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: param_groups}]\n",
      "\u001b[0;31mValueError\u001b[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "model = FcClassifier().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_loader, val_loader, device, optimizer, n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc, test_loss = test(model, test_loader, device)\n",
    "print(f\"Test loss: {test_loss}, Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    # TODO: Implement the convolutional neural network with the following architecture\n",
    "    #       - 5×5 Convolutional Layer with 32 filters, stride 1 and padding 2.\n",
    "    #       - ReLU Activation Layer.\n",
    "    #       - 2×2 Max Pooling Layer with a stride of 2.\n",
    "    #       - 3×3 Convolutional Layer with 64 filters, stride 1 and padding 1.\n",
    "    #       - ReLU Activation Layer.\n",
    "    #       - 2×2 Max Pooling Layer with a stride of 2。\n",
    "    #       - Fully-connected layer with 1024 output units.\n",
    "    #       - ReLU Activation Layer.\n",
    "    #       - Fully-connected layer with 10 output units.\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_loader, val_loader, device, optimizer, n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc, test_loss = test(model, test_loader, device)\n",
    "print(f\"Test loss: {test_loss}, Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization and predictions\n",
    "classes = ('お', 'き', 'す', 'つ', 'な', 'は', 'ま', 'や', 'れ', 'を')\n",
    "img, label = test_dataset[6]\n",
    "plt.imshow(img.squeeze(0), cmap=\"gray\")\n",
    "plt.show()\n",
    "img = img.to(device)\n",
    "pred = int(torch.argmax(model(img.unsqueeze(0)), dim=1)[0])\n",
    "print(f\"Model prediction: {classes[label]}\\nGround truth: {classes[label]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a deeper CNN model for a higher classification accuracy\n",
    "**NOTE: This part would require GPU computing power. You may skip this part during the lab.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCNN(nn.Module):\n",
    "    # TODO: Implement the convolutional neural network with more layers than the previous one.\n",
    "    #       Test the model accuracy and see whether there is a performance gain.\n",
    "    def __init__(self):\n",
    "        super(DeepCNN, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepCNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_loader, val_loader, device, optimizer, n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc, test_loss = test(model, test_loader, device)\n",
    "print(f\"Test loss: {test_loss}, Test accuracy: {test_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "16fb029d2d2f281c76137439d9122480f0701165270269ef0c874281e28a4d48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
