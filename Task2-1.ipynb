{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "import scipy\n",
    "from skimage import transform\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import sklearn\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision import transforms,datasets\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one way from tut and chatGPT\n",
    "\n",
    "# NOTE: transformation defined for this classification task, data augmentation techniques used during training.\n",
    "#       To understand each transformation, please read https://pytorch.org/vision/stable/transforms.html\n",
    "#       - (Normalize data to range between [-1, 1])\n",
    "#       - (Randomly flip the image left to right)\n",
    "#       - (Zero-pad 4 pixels on each side and randomly crop 28x28 as input)\n",
    "# train_transforms = T.Compose([\n",
    "#     T.ToTensor(),\n",
    "#     T.Normalize((0.5,), (0.5,)),\n",
    "#     T.RandomCrop(size=(28, 28), padding=4),\n",
    "# ])\n",
    "\n",
    "# test_transforms = T.Compose([\n",
    "#     T.ToTensor(),\n",
    "#     T.Normalize((0.5,), (0.5,)),\n",
    "# ])\n",
    "\n",
    "# Define data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DomainNetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, domain, split='train', transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.domain = domain\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.data = datasets.ImageFolder(root=root_dir, transform=transform)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.data[idx]\n",
    "        return img, label\n",
    "\n",
    "# Dataset paths\n",
    "real_train_path = 'data/real_train'\n",
    "real_test_path = 'data/real_test'\n",
    "sketch_train_path = 'data/sketch_train'\n",
    "sketch_test_path = 'data/sketch_test'\n",
    "\n",
    "# Create datasets\n",
    "real_train_dataset = DomainNetDataset(root_dir=real_train_path, domain='real', split='train', transform=data_transforms['train'])\n",
    "real_test_dataset = DomainNetDataset(root_dir=real_test_path, domain='real', split='test', transform=data_transforms['test'])\n",
    "sketch_train_dataset = DomainNetDataset(root_dir=sketch_train_path, domain='sketch', split='train', transform=data_transforms['train'])\n",
    "sketch_test_dataset = DomainNetDataset(root_dir=sketch_test_path, domain='sketch', split='test', transform=data_transforms['test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/anaconda3/envs/pythonforcomputervision/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda/anaconda3/envs/pythonforcomputervision/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Load pretrained ResNet-34 model\n",
    "resnet34 = models.resnet34(pretrained=True)\n",
    "\n",
    "# Modify final fully-connected layer\n",
    "num_classes = 10  # Number of classes for this task\n",
    "num_ftrs = resnet34.fc.in_features\n",
    "resnet34.fc = nn.Linear(num_ftrs, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/real_train/tree/data_batch_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#one way from lecture\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 创建自定义数据集\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m training_data \u001b[38;5;241m=\u001b[39m \u001b[43mCustomDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/real_train/tree\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 创建数据加载器，并指定批次大小\u001b[39;00m\n\u001b[1;32m      6\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n",
      "Cell \u001b[0;32mIn[8], line 50\u001b[0m, in \u001b[0;36mCustomDataset.__init__\u001b[0;34m(self, data_path, kind)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_list:\n\u001b[1;32m     49\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m data_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m file_name  \u001b[38;5;66;03m# 使用字符串拼接构建文件路径\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages\u001b[38;5;241m.\u001b[39mappend(images)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels\u001b[38;5;241m.\u001b[39mappend(labels)\n",
      "Cell \u001b[0;32mIn[8], line 18\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(data_path, file_name)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# file_path = os.path.join(data_path, file_name)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m file_path \u001b[38;5;241m=\u001b[39m data_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m file_name  \u001b[38;5;66;03m# 使用字符串拼接构建文件路径\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# load data with pickle\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     entry \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m     images \u001b[38;5;241m=\u001b[39m entry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/Applications/anaconda/anaconda3/envs/pythonforcomputervision/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/real_train/tree/data_batch_1'"
     ]
    }
   ],
   "source": [
    "#one way from lecture\n",
    "# 创建自定义数据集\n",
    "training_data = CustomDataset(data_path='data/real_train/tree', kind='train')\n",
    "\n",
    "# 创建数据加载器，并指定批次大小\n",
    "batch_size = 32\n",
    "data_loader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 循环迭代数据加载器，加载批次数据\n",
    "for batch_idx, (images, labels) in enumerate(data_loader):\n",
    "    # 在这里进行模型训练等操作\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"tree\",\n",
    "    1: \"automobile\",\n",
    "    2: \"bird\",\n",
    "    3: \"cat\",\n",
    "    4: \"deer\",\n",
    "    5: \"dog\",\n",
    "    6: \"frog\",\n",
    "    7: \"horse\",\n",
    "    8: \"ship\",\n",
    "    9: \"truck\",\n",
    "}\n",
    "# helper function to load CIFAR-10 data\n",
    "def load_data(data_path, file_name):\n",
    "    \"\"\"Load CIFAR-10 data from given data_path\"\"\"\n",
    "    # file_path = os.path.join(data_path, file_name)\n",
    "    file_path = data_path + '/' + file_name  # 使用字符串拼接构建文件路径\n",
    "    with open(file_path, 'rb') as f:\n",
    "        # load data with pickle\n",
    "        entry = pickle.load(f, encoding='latin1')\n",
    "        images = entry['data']\n",
    "        labels = entry['labels']\n",
    "        # reshape the array to 32x32 color image\n",
    "        images = images.reshape(-1, 3, 32, 32)  # '-1' means the value will be deduced from the shape of array\n",
    "    return images, labels\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_path, kind='train'):\n",
    "        super().__init__()\n",
    "        train_list = ['data_batch_1', 'data_batch_2','data_batch_3','data_batch_4']\n",
    "        valid_list = ['data_batch_5']\n",
    "        test_list = ['test_batch']\n",
    "\n",
    "        if kind == 'train':\n",
    "            self.file_list = train_list\n",
    "        elif kind == 'valid':\n",
    "            self.file_list = valid_list\n",
    "        else:\n",
    "            self.file_list = test_list\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        # for file_name in self.file_list:\n",
    "        #     file_path = os.path.join(data_path, file_name)\n",
    "        #     images, labels = load_data(data_path, file_name)\n",
    "        #     self.images.append(images)\n",
    "        #     self.labels.append(labels)\n",
    "\n",
    "        for file_name in self.file_list:\n",
    "            file_path = data_path + '/' + file_name  # 使用字符串拼接构建文件路径\n",
    "            images, labels = load_data(data_path, file_name)\n",
    "            self.images.append(images)\n",
    "            self.labels.append(labels)\n",
    "\n",
    "        # concatenate the data together\n",
    "        self.images = np.concatenate(self.images, axis=0)   # NCHW\n",
    "        self.images = self.images.transpose((0, 2, 3, 1))   # convert to HWC\n",
    "        self.labels = np.concatenate(self.labels, axis=0)\n",
    "   \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "       image = self.images[idx]\n",
    "       label = self.labels[idx]\n",
    "       \n",
    "       return image, label \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/real_train/tree/data_batch_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_data \u001b[38;5;241m=\u001b[39m \u001b[43mCustomDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/real_train/tree\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m figure \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m      3\u001b[0m cols, rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m\n",
      "Cell \u001b[0;32mIn[8], line 50\u001b[0m, in \u001b[0;36mCustomDataset.__init__\u001b[0;34m(self, data_path, kind)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_list:\n\u001b[1;32m     49\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m data_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m file_name  \u001b[38;5;66;03m# 使用字符串拼接构建文件路径\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages\u001b[38;5;241m.\u001b[39mappend(images)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels\u001b[38;5;241m.\u001b[39mappend(labels)\n",
      "Cell \u001b[0;32mIn[8], line 18\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(data_path, file_name)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# file_path = os.path.join(data_path, file_name)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m file_path \u001b[38;5;241m=\u001b[39m data_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m file_name  \u001b[38;5;66;03m# 使用字符串拼接构建文件路径\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# load data with pickle\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     entry \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m     images \u001b[38;5;241m=\u001b[39m entry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/Applications/anaconda/anaconda3/envs/pythonforcomputervision/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/real_train/tree/data_batch_1'"
     ]
    }
   ],
   "source": [
    "training_data = CustomDataset(data_path='data/real_train/tree', kind='train')\n",
    "figure = plt.figure(figsize=(8,8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols*rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    ax = figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis('off')\n",
    "    ax.imshow(img.squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
